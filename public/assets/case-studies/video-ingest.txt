The Client: A global video marketing agency within the manufacturing sector

The Task: To somehow unify, organise, archive and dissemeninate terrabytes of active and historical video files. Previously video files were local to each editors' workstation, and video files for ingest were posted to and from the central office. There was no archive system in place other than consumer external harddrives numbering in the dozens. Data loss was common. Searching was impossible. Gettign access to a particular clip could take weeks, or not at all.

The Execution: After extensive research across a number of different vendors and hardware providors, and being frankly astounded by the cost, and lack of basic functionality even when the product was in the tens of thousands of pounds per year, i instead opted to deploy my own. I was able to source two QNAP storage units each with 100TB of data. One was placed in the office, and the other at a remote location. I then implemented the QNAP's backup software HBS3 to sync constantly with Dropbox. MEaning that any file could be ingested anywehre within the world, and would immediately download to the central server. Likewise, anything could be ingested in the office on the connected machines on 10GB LAN connections, and be available worldwide almost instantaneously thanks to our 1GB leased line. A batch script runs on an office terminal that polls for new files every hours, it then creates proxy files at just 5% of the original filesize. Meaning a remote editor on a poor internet connection could start working editing on proxy files while the full fat media would download in the background. For ultimate fallover, the second remote QNAP downloads from the main server every night, meaning that we would have a replacement system should the first one fail for any reason whatsoever. Archiving is handled by S3 Glacier storage. Again after much research into arcive systems and file storage, this was deemed as the most cost effective and robust solution. Periodically archived files are required from S3, but the egress cost per file is fractions of a penny. 

The Result: Cost saving aside, our editing operations have become much much faster. No longer waiting on post for cards, no longer at risj of losing data. This centralised system has transformed the business. File recovery and search is instantaneous again thanks to the 1GB leased line, and 10GB internal network. Our editors locally can now edit 4K source files at incredible speeds, and remote editors know that all data is safe whereever they are. Any project can be picked up my any editor around the world,. Meaning no more local stroage, no more requesting files to be sent. Everything is available, at all times.